# -*- coding: utf-8 -*-
"""titanic.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1BQcowZe5dc7PrgKYlBNMjcLkvO5EVV88
"""



#import libraries
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
# %matplotlib inline
import math
import sklearn as sk
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import classification_report
from sklearn.metrics import confusion_matrix
from sklearn.metrics import accuracy_score

#set display options
pd.set_option("display.max_columns", None)
pd.set_option("display.max_rows", 200)

df = pd.read_csv("/Users/niambashambu/Desktop/CSCI  1300/CS LAB/titanic (2).csv")
print(len(df))
df.head(5)

"""## Part 1: Introduction"""

#graph of survived
sns.countplot(data=df, x="Survived")
print(df.Survived.value_counts())

sns.countplot(data=df, x="Survived", hue="Sex")

#group survived by sex, then only show sex columns (sex columns have survived values)
print(df.groupby(["Survived", "Sex"])["Sex"].value_counts())
print("-" * 50)
#get a pivot table that shows counts (aggfunc) of Survived x Sex, each row is different by PassengerId
print(df.pivot_table(index="Survived", columns="Sex", values="PassengerId", aggfunc="count"))

sns.countplot(data=df, x="Survived", hue="Pclass")

print(df.pivot_table(index="Survived", columns="Pclass", values="PassengerId", aggfunc="count"))

grouped = df.groupby(["Survived", "Age"])["Age"].count()

for index, count in grouped.items():
    print(f"Survived: {index[0]}, Age: {index[1]}, Count: {count}")

df.isnull().sum() #get number of NaN
sns.heatmap(df.isnull(), cmap="YlGnBu") #each row is a different row, blue lines = null values
# (cmap="YlGnBu" is for color, Yellow --> Green --> Blue)

sns.boxplot(data=df, x="Pclass", y="Age")
#first class passengers are generally older

"""## Part 2: Data Cleaning"""

df.dropna(inplace=True)
df.isnull().sum()

#one-hot encoding for Sex (male/female --> 0/1)
sex = pd.get_dummies(data=df["Sex"])

#same thing for embarked
embark = pd.get_dummies(df["Embarked"], drop_first=True) #drop_first=True removes the first option for categories

#and pclass
pcl = pd.get_dummies(df["Pclass"], drop_first=True)

#now add them to the df
df = pd.concat([df, sex, embark, pcl], axis=1)
df.head(5)

#now remove prev columns and string variables
df.drop(["Pclass", "Sex", "Embarked", "Name", "Ticket", "Cabin"], axis=1, inplace=True)
df

"""## Part 3: Train and Test"""

#graph logistic reg model of survival
x = df.drop("Survived", axis=1)
y = df["Survived"]

#split the dataset
xtrain, xtest, ytrain, ytest = train_test_split(x, y, test_size=0.3, random_state=1)

logmodel = LogisticRegression(max_iter=1000, C=1.0)

logmodel.fit(xtrain, ytrain)

predictions = logmodel.predict(xtest)

confusion_matrix(ytest, predictions)

accuracy_score(ytest, predictions) #76.4% --> not too bad