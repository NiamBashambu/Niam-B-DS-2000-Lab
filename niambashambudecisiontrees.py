# -*- coding: utf-8 -*-
"""NiamBashambuDecisionTrees

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1GIM399qMRULsRvC2J0rV5_QyVUEDT2SK
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

from sklearn.model_selection import train_test_split
from sklearn.tree import DecisionTreeClassifier
from sklearn import tree
from sklearn.model_selection import GridSearchCV
from sklearn.metrics import (
    f1_score,
    accuracy_score,
    recall_score,
    precision_score,
    confusion_matrix,
    make_scorer,
)
pd.set_option("display.max_columns", None)
pd.set_option("display.max_rows", 200)




df = pd.read_csv("/Users/niambashambu/Desktop/CSCI  1300/CS LAB/online_shoppers_intention_given (2).csv")
df

df.head()

df.tail()

df.shape

df1=df.copy()

df1[df1.duplicated()].count()

df1.drop_duplicates(inplace=True)

df1.info()

df1.isnull().sum()

df1.describe(include=["object", "bool"])

cat_columns = list(df1.select_dtypes(include=['object','bool']).columns)

num_columns = list(df1.select_dtypes(include=['int64', 'float64']).columns)

print(cat_columns)
print(num_columns)

cat_columns = ["Month", "VisitorType", "Weekend", "Revenue"]
for i in cat_columns:
    print(df1[i].value_counts())
    print("*" * 50)

#may had the most activity
#most people were returning
  #what would other be in this case?
#weekdays were the most busy which is surprising because online shopping doesn't seem like it would happen on a weekday but rather when a person would have more time.
#only about 1900 customers create revenue for this site.

df1.describe().T

#most time spent on product related pages
#least time spent on the informational related pages
#very right skewed data i believe but im not 100% sure



def histogram_boxplot(data, feature, figsize=(15, 10), kde=False, bins=None):
    """
    Boxplot and histogram combined

    data: dataframe
    feature: dataframe column
    figsize: size of figure (default (15,10))
    kde: whether to show the density curve (default False)
    bins: number of bins for histogram (default None)
    """
    f2, (ax_box2, ax_hist2) = plt.subplots(
        nrows=2,  # Number of rows of the subplot grid= 2
        sharex=True,  # x-axis will be shared among all subplots
        gridspec_kw={"height_ratios": (0.25, 0.75)},
        figsize=figsize,
    )  # creating the 2 subplots
    sns.boxplot(
        data=df1, x=feature, ax=ax_box2, showmeans=True, color="violet"
    )  # boxplot will be created and a star will indicate the mean value of the column
    sns.histplot(
        data=df1, x=feature, kde=kde, ax=ax_hist2, bins=bins, palette="winter"
    ) if bins else sns.histplot(
        data=df1, x=feature, kde=kde, ax=ax_hist2
    )  # For histogram
    ax_hist2.axvline(
        df1[feature].mean(), color="green", linestyle="--"
    )  # Add mean to the histogram
    ax_hist2.axvline(
        df1[feature].median(), color="black", linestyle="-"
    )  # Add median to the histogram

histogram_boxplot(df1, "Administrative_Duration", bins=70)
#right skewed
#lots of outliers

histogram_boxplot(df1, "Informational")
#also right skewed unsurpisingly
#also many outliers

histogram_boxplot(df1, "Informational_Duration")
#right skewed
#outliers

histogram_boxplot(df1, "ProductRelated")
#right skewed

histogram_boxplot(df1, "ProductRelated_Duration")
#outliers and right skewed

histogram_boxplot(df1, "BounceRates")
#right skewed and outliers

histogram_boxplot(df1, "ExitRates")
#right skewed and outliers

histogram_boxplot(df1, "Region")
#outliers and right skewed

histogram_boxplot(df1, "TrafficType")
#right skewed but not as much and outliers

df1 = df1.drop(["PageValues"], axis=1)

df2 = pd.get_dummies(
    df1,
    columns=[
        "Month",
        "VisitorType",
        "Weekend",
        "Region",
        "Browser",
        "OperatingSystems",
        "SpecialDay",
    ],
    drop_first=True,
)
df2.head()

X = df2.drop("Revenue", axis=1)
y = df2["Revenue"].astype("int64")

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1)
print(X_train.shape, X_test.shape)

def get_recall_score(model, predictors, target):
    prediction = model.predict(predictors)
    return recall_score(target, prediction)

def confusion_matrix_sklearn(model, predictors, target):
    y_predictors = model.predict(predictors)
    cm = confusion_matrix(target, y_predictors)
    labels = np.asarray(
        [
            ["{0:0.0f}".format(item) + "\n{0:.2%}".format(item / cm.flatten().sum())]
            for item in cm.flatten()
        ]
    ).reshape(2, 2)

    plt.figure(figsize=(6, 4))
    sns.heatmap(cm, annot=labels, fmt="")
    plt.ylabel("True label")
    plt.xlabel("Predicted label")

model = DecisionTreeClassifier(
    criterion="gini", class_weight={0: 0.15, 1: 0.85}, random_state=1
)

model.fit(X_train, y_train)

confusion_matrix_sklearn(model, X_test, y_test)

decision_tree_perf_test = get_recall_score(model, X_test, y_test)
print("Recall Score:", decision_tree_perf_test)

plt.figure(figsize=(20, 30))
out = tree.plot_tree(
    model,
    feature_names=X_train.columns.to_list(),
    filled=True,
    fontsize=9,
    node_ids=False,
    class_names=None,
)